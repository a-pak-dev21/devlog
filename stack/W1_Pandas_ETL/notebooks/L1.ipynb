{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5372e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd473879",
   "metadata": {},
   "source": [
    "### Level 1:\n",
    "### Block of solving and studying pandas core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de013d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solution:\n",
    "\n",
    "    def __init__(self, input_file: str) -> None:\n",
    "        self.root_dir = Path.cwd().parent\n",
    "        self.file_dir = self.root_dir / \"data\" / input_file\n",
    "        self.df = pd.read_csv(self.file_dir)\n",
    "\n",
    "    def _create_path(self, folder_name: str, file_name: str) -> Path:\n",
    "        folder_dir = self.root_dir / folder_name\n",
    "        folder_dir.mkdir(exist_ok=True)\n",
    "        file_dir = folder_dir / Path(file_name)\n",
    "        return file_dir\n",
    "\n",
    "    # Filter only rows where duration_min > 25, \n",
    "    # sort this rows in descending order,\n",
    "    # save result into solutions/L1_filtered.xlsx\n",
    "    def L1_task_1(self, file_name: str) -> None:\n",
    "        result = self.df[self.df[\"duration_min\"] > 25]\n",
    "        result = result.sort_values(\"weight_kg\", ascending=False)\n",
    "        file_dir = self._create_path(\"solutions\", file_name)\n",
    "        result.to_excel(file_dir, index=False)\n",
    "    \n",
    "    # Group all trainings by cities \n",
    "    # for each group find average weight, total repeat, amount of unique users\n",
    "    # Save result into solutions/L1_summary.xlsx\n",
    "    def L1_task_2(self, file_name: str) -> None:\n",
    "        grouped_by_cities = self.df.groupby(\"city\").agg({\n",
    "            \"weight_kg\": \"mean\",\n",
    "            \"reps\": \"sum\",\n",
    "            \"user_id\": \"nunique\"\n",
    "        })\n",
    "        file_dir = self._create_path(\"solutions\", file_name)\n",
    "        grouped_by_cities.to_excel(file_dir, index=False)\n",
    "\n",
    "    # Filter rows where body_part != \"cardio\"\n",
    "    # group by body_part and display:\n",
    "    #   average weight and average reps\n",
    "    # Save in solutions/L1_report.xlsx\n",
    "    def L1_task_3(self, file_name: str):\n",
    "        no_cardio = self.df[self.df[\"body_part\"] != \"cardio\"]\n",
    "        grouped_by_body_part = no_cardio.groupby(\"body_part\").agg({\n",
    "            \"weight_kg\": \"mean\",\n",
    "            \"reps\": \"mean\"\n",
    "        })\n",
    "        file_dir = self._create_path(\"solutions\", file_name)\n",
    "        grouped_by_body_part.to_excel(file_dir, index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4b7f48b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_var = Solution(\"workouts.csv\")\n",
    "my_var.L1_task_1(\"L1_filtered.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "65af285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_var = Solution(\"workouts.csv\")\n",
    "my_var.L1_task_2(\"L1_grouped.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "036e7dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_var = Solution(\"workouts.csv\")\n",
    "my_var.L1_task_3(\"L1_summary.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb08b436",
   "metadata": {},
   "source": [
    "### Level 2:\n",
    "### Advanced pandas methods for to manipulate tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "8ee3a17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solution_2:\n",
    "    \n",
    "    def __init__(self, file_name: str, dim_name: str) -> None:\n",
    "        self.root_dir = Path.cwd().parent\n",
    "        self.file_dir = self.root_dir / \"data\" / Path(file_name)\n",
    "        self.dim_dir = self.root_dir / \"data\" / Path(dim_name)\n",
    "        self.df = pd.read_csv(self.file_dir)\n",
    "        self.dim = pd.read_csv(self.dim_dir)\n",
    "    \n",
    "    def _path_constructor(self, folder_name: str, file_name: str) -> Path:\n",
    "        folder_dir = self.root_dir / folder_name\n",
    "        folder_dir.mkdir(exist_ok=True)\n",
    "        file_dir = folder_dir / file_name\n",
    "        return file_dir\n",
    "\n",
    "    @staticmethod     \n",
    "    def _weight_compare(row: pd.Series):\n",
    "        return \"Above / equal average\" if row[\"weight_kg\"] >= row[\"avg_weight_city\"] else \"Below average\"\n",
    "    \n",
    "    # Fix \"dim\" file by removing invalid rows, \n",
    "    # merge my file and dim by city, with validating it in \"m:1\" sequence, with indicator\n",
    "    # after merging if there are cities which appear only in left table, return them and their amount\n",
    "    # replace them in table with \"Unknown\"\n",
    "    # final result save as \"solutions/L2_joined.xlsx\"\n",
    "    def L2_task_1(self, file_name: str, invalid_file: str):\n",
    "        self.dim[\"country\"] = self.dim[\"country\"].astype(\"string\")\n",
    "        invalidity_mask = self.dim[\"country\"].isna() | (self.dim[\"country\"].str.strip() == \"\")\n",
    "        invalid_rows = self.dim[invalidity_mask]\n",
    "        invalid_rows.to_excel(self._path_constructor(\"invalid_datas\", invalid_file))\n",
    "        valid_dim = self.dim[~invalidity_mask]\n",
    "        merged_df = self.df.merge(valid_dim,\n",
    "                                  how=\"left\",\n",
    "                                  on=\"city\",\n",
    "                                  suffixes=(\"_left\", \"_right\"),\n",
    "                                  validate=\"m:1\",\n",
    "                                  indicator=True)\n",
    "        \n",
    "        invalid_cities_mask = merged_df[\"_merge\"] == \"left_only\"\n",
    "        invalid_cities_amount = merged_df[invalid_cities_mask].shape[0]\n",
    "        merged_df.loc[invalid_cities_mask, \"city\"] = \"Unknown\"\n",
    "        right_cols = [c for c in valid_dim.columns if c != \"city\"]\n",
    "        merged_df = merged_df.drop(columns=right_cols, errors=\"ignore\")\n",
    "        merged_df = merged_df.merge(valid_dim,\n",
    "                                  how=\"left\",\n",
    "                                  on=\"city\",\n",
    "                                  suffixes=(\"_left\", \"_right\"),\n",
    "                                  validate=\"m:1\",\n",
    "                                  indicator=\"my_col\")\n",
    "        file_dir = self._path_constructor(\"solutions\", \"L2_joined.xlsx\")\n",
    "        merged_df.to_excel(file_dir, index=False)\n",
    "    \n",
    "    # Challenge to change Wide format - Разобрать, нихуя не понял\n",
    "    # def L2_task_2(self) -> pd.DataFrame:\n",
    "    #     self.df.melt(id_vars=[\"user_id\"], var_name=)\n",
    "\n",
    "\n",
    "    # Add new column avg_weight_city, found for each city\n",
    "    # compare for each row if its own value is higher then average for city\n",
    "    # save new result with new column to solutions/L2_transform.xlsx\n",
    "    def L2_task_3(self) -> None:\n",
    "        try:\n",
    "            self.df[\"weight_kg\"] = self.df[\"weight_kg\"].astype(float)\n",
    "        except ValueError:\n",
    "            raise  ValueError(\"All values in column 'weight_kg' have to be convertable to numeric values\")\n",
    "        \n",
    "        self.df[\"avg_weight_city\"] = self.df.groupby(\"city\")[\"weight_kg\"].transform(\"mean\")\n",
    "        self.df[\"compared_to_avg\"] = self.df.apply(self._weight_compare, axis=1)\n",
    "        file_dir = self._path_constructor(\"solutions\", \"L2_transform.xlsx\")\n",
    "        self.df.to_excel(file_dir)\n",
    "\n",
    "    \n",
    "    # Take column body_part and modify it by using pd.Categorical\n",
    "    # Make my own order for categories for ex.: [\"cardio\", \"legs\", \"back\", \"chest\"]\n",
    "    # Sort dataset by this order\n",
    "    # save result into solutions/L2_categorical.xlsx\n",
    "    def L2_task_4(self) -> None:\n",
    "        self.df[\"body_part\"] = pd.Categorical(self.df[\"body_part\"], categories=[\"chest\", \"biceps\", \"back\", \"abs\", \"shoulders\", \"legs\", \"cardio\"], ordered=True)\n",
    "        self.df = self.df.sort_values(\"body_part\")\n",
    "        file_dir = self._path_constructor(\"solutions\", \"L2_categorical.xlsx\")\n",
    "        self.df.to_excel(file_dir, index=False)\n",
    "        \n",
    "    # Find rows with same value in (user_id, exercise_name)\n",
    "    # Delete duplicates, and remain 1st appereance of this \n",
    "    # save fixed dataset in solutions/L2_deduplicated.xlsx\n",
    "    def L2_task_5(self) -> None:\n",
    "        self.df = self.df.drop_duplicates(subset=[\"user_id\", \"exercise\"])\n",
    "        file_dir = self._path_constructor(\"solutions\", \"L2_deduplicated.xlsx\")\n",
    "        self.df.to_excel(file_dir, index=False)\n",
    "\n",
    "    # transform all date values into datetime objects \n",
    "    # Create separate columns for year, month, day \n",
    "    # Save result into solutions/L2_dates.xlsx\n",
    "    def L2_task_6(self):\n",
    "        self.df[\"date\"] = pd.to_datetime(self.df[\"date\"], errors=\"coerce\", format=\"%Y-%m-%d\")\n",
    "        self.df[\"year\"] = self.df[\"date\"].dt.year\n",
    "        self.df[\"month\"] = self.df[\"date\"].dt.month\n",
    "        self.df[\"day\"] = self.df[\"date\"].dt.day\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "7399c11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_var_2 = Solution_2(\"workouts.csv\", \"cities_lookup.csv\")\n",
    "my_var_2.L2_task_1(\"L2_summary.xlsx\", \"L2_task_1_inv_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "b1856d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_var_2 = Solution_2(\"workouts.csv\", \"cities_lookup.csv\")\n",
    "my_var_2.L2_task_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "07e40e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_var_2 = Solution_2(\"workouts.csv\", \"cities_lookup.csv\")\n",
    "my_var_2.L2_task_4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "87bb3d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_var_2 = Solution_2(\"workouts.csv\", \"cities_lookup.csv\")\n",
    "my_var_2.L2_task_5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "fdc91889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>city</th>\n",
       "      <th>exercise</th>\n",
       "      <th>body_part</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>reps</th>\n",
       "      <th>duration_min</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>Prague</td>\n",
       "      <td>Barbell Squat</td>\n",
       "      <td>legs</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>2025</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>2025-08-03</td>\n",
       "      <td>New York</td>\n",
       "      <td>Bench Press</td>\n",
       "      <td>chest</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>2025</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>2025-08-02</td>\n",
       "      <td>London</td>\n",
       "      <td>Deadlift</td>\n",
       "      <td>back</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>2025</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103</td>\n",
       "      <td>2025-08-02</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Pull Ups</td>\n",
       "      <td>back</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>2025</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>2025-08-05</td>\n",
       "      <td>Prague</td>\n",
       "      <td>Running</td>\n",
       "      <td>cardio</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2025</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>102</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>London</td>\n",
       "      <td>Overhead Press</td>\n",
       "      <td>shoulders</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>2025</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>103</td>\n",
       "      <td>2025-08-07</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Leg Press</td>\n",
       "      <td>legs</td>\n",
       "      <td>120</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>2025</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>103</td>\n",
       "      <td>2025-10-12</td>\n",
       "      <td>Jamaika</td>\n",
       "      <td>Pull Ups</td>\n",
       "      <td>legs</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2025</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id       date      city        exercise  body_part  weight_kg  reps  \\\n",
       "0      101 2025-08-01    Prague   Barbell Squat       legs         80     5   \n",
       "1      101 2025-08-03  New York     Bench Press      chest         60     8   \n",
       "2      102 2025-08-02    London        Deadlift       back        100     3   \n",
       "3      103 2025-08-02    Berlin        Pull Ups       back          0    12   \n",
       "4      101 2025-08-05    Prague         Running     cardio          0     0   \n",
       "5      102 2025-06-05    London  Overhead Press  shoulders         40     6   \n",
       "6      103 2025-08-07    Berlin       Leg Press       legs        120     8   \n",
       "7      103 2025-10-12   Jamaika        Pull Ups       legs          1    11   \n",
       "\n",
       "   duration_min  year  month  day  \n",
       "0            40  2025      8    1  \n",
       "1            35  2025      8    3  \n",
       "2            30  2025      8    2  \n",
       "3            20  2025      8    2  \n",
       "4            25  2025      8    5  \n",
       "5            25  2025      6    5  \n",
       "6            30  2025      8    7  \n",
       "7            11  2025     10   12  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_var_2 = Solution_2(\"workouts.csv\", \"cities_lookup.csv\")\n",
    "my_var_2.L2_task_6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ed753d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
